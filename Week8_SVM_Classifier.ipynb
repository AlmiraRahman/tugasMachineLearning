{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week8_SVM_Classifier",
      "provenance": [],
      "authorship_tag": "ABX9TyNbIXkF3gEOnDNVX9u9dlif",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlmiraRahman/tugasMachineLearning/blob/main/Week8_SVM_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zerfEVQWIjeF"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # for data visualization\n",
        "import seaborn as sns # for statistical data visualization\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "kakA35ymJYIi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = '/content/pulsar_stars.csv'\n",
        "\n",
        "df = pd.read_csv(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "MnM8WHPEJyDV",
        "outputId": "adf148a8-01a9-4221-cdc3-1cbd58af60c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4e1ec189b27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/pulsar_stars.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/pulsar_stars.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view dimensions of dataset\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "62OErrLyO-vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's preview the dataset\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "KpD1WgPzPA-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the column names of the dataframe\n",
        "\n",
        "col_names = df.columns\n",
        "\n",
        "col_names"
      ],
      "metadata": {
        "id": "Zw62t3yAPDaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove leading spaces from column names\n",
        "\n",
        "df.columns = df.columns.str.strip()"
      ],
      "metadata": {
        "id": "cLOPy3EcP69D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view column names again\n",
        "\n",
        "df.columns"
      ],
      "metadata": {
        "id": "f33aeCf6P8Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename column names\n",
        "\n",
        "df.columns = ['IP Mean', 'IP Sd', 'IP Kurtosis', 'IP Skewness', \n",
        "              'DM-SNR Mean', 'DM-SNR Sd', 'DM-SNR Kurtosis', 'DM-SNR Skewness', 'target_class']"
      ],
      "metadata": {
        "id": "MEVppFhMP_Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the renamed column names\n",
        "\n",
        "df.columns"
      ],
      "metadata": {
        "id": "GPzeIXBMRI14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check distribution of target_class column\n",
        "\n",
        "df['target_class'].value_counts()"
      ],
      "metadata": {
        "id": "wUh9KB-DRLcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the percentage distribution of target_class column\n",
        "\n",
        "df['target_class'].value_counts()/np.float(len(df))"
      ],
      "metadata": {
        "id": "cvk0FPIGROFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view summary of dataset\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "Cikz4KhpRQBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values in variables\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "9rhsL1Z4RU4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view summary statistics in numerical variables\n",
        "\n",
        "round(df.describe(),2)"
      ],
      "metadata": {
        "id": "TEd0_dRSRXgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# draw boxplots to visualize outliers\n",
        "\n",
        "plt.figure(figsize=(24,20))\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 1)\n",
        "fig = df.boxplot(column='IP Mean')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Mean')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "fig = df.boxplot(column='IP Sd')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Sd')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 3)\n",
        "fig = df.boxplot(column='IP Kurtosis')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Kurtosis')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 4)\n",
        "fig = df.boxplot(column='IP Skewness')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Skewness')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 5)\n",
        "fig = df.boxplot(column='DM-SNR Mean')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Mean')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 6)\n",
        "fig = df.boxplot(column='DM-SNR Sd')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Sd')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 7)\n",
        "fig = df.boxplot(column='DM-SNR Kurtosis')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Kurtosis')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 8)\n",
        "fig = df.boxplot(column='DM-SNR Skewness')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Skewness')"
      ],
      "metadata": {
        "id": "FsLH2smoRcLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot histogram to check distribution\n",
        "\n",
        "\n",
        "plt.figure(figsize=(24,20))\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 1)\n",
        "fig = df['IP Mean'].hist(bins=20)\n",
        "fig.set_xlabel('IP Mean')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "fig = df['IP Sd'].hist(bins=20)\n",
        "fig.set_xlabel('IP Sd')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 3)\n",
        "fig = df['IP Kurtosis'].hist(bins=20)\n",
        "fig.set_xlabel('IP Kurtosis')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 4)\n",
        "fig = df['IP Skewness'].hist(bins=20)\n",
        "fig.set_xlabel('IP Skewness')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 5)\n",
        "fig = df['DM-SNR Mean'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Mean')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 6)\n",
        "fig = df['DM-SNR Sd'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Sd')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 7)\n",
        "fig = df['DM-SNR Kurtosis'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Kurtosis')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 8)\n",
        "fig = df['DM-SNR Skewness'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Skewness')\n",
        "fig.set_ylabel('Number of pulsar stars')\n"
      ],
      "metadata": {
        "id": "YFekdfBERhdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['target_class'], axis=1)\n",
        "\n",
        "y = df['target_class']"
      ],
      "metadata": {
        "id": "s6Spnz35Rju6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split X and y into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
      ],
      "metadata": {
        "id": "zoFDElLcRlN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape of X_train and X_test\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "sXDU4o9jRnJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = X_train.columns"
      ],
      "metadata": {
        "id": "Tvk0QFqWRo9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "jwBHfRRXRqKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.DataFrame(X_train, columns=[cols])"
      ],
      "metadata": {
        "id": "2dgptNEZRsgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = pd.DataFrame(X_test, columns=[cols])"
      ],
      "metadata": {
        "id": "qS_1UE5iRuw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.describe()"
      ],
      "metadata": {
        "id": "IE0bcRC8Rw9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import SVC classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# import metrics to compute accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# instantiate classifier with default hyperparameters\n",
        "svc=SVC() \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "7WOUSWmFRydX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate classifier with rbf kernel and C=100\n",
        "svc=SVC(C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "5gxGYjciRz6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate classifier with rbf kernel and C=1000\n",
        "svc=SVC(C=1000.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with rbf kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "rCLBOo6-R4XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate classifier with linear kernel and C=1.0\n",
        "linear_svc=SVC(kernel='linear', C=1.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred_test=linear_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\n"
      ],
      "metadata": {
        "id": "Q_AVgeC6R6Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate classifier with linear kernel and C=100.0\n",
        "linear_svc100=SVC(kernel='linear', C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc100.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=linear_svc100.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "aI65PGAQR8eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate classifier with linear kernel and C=1000.0\n",
        "linear_svc1000=SVC(kernel='linear', C=1000.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc1000.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=linear_svc1000.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "2RjjDsQSR-He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = linear_svc.predict(X_train)\n",
        "\n",
        "y_pred_train"
      ],
      "metadata": {
        "id": "6jbb-GroR_78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ],
      "metadata": {
        "id": "PHBZo-ZeSBdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the scores on training and test set\n",
        "\n",
        "print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(linear_svc.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "sZhMe2YiSCil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check class distribution in test set\n",
        "\n",
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "SYqy3KFVSFFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check null accuracy score\n",
        "\n",
        "null_accuracy = (3306/(3306+274))\n",
        "\n",
        "print('Null accuracy score: {0:0.4f}'. format(null_accuracy))"
      ],
      "metadata": {
        "id": "lBrLwwUOSHup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate classifier with polynomial kernel and C=1.0\n",
        "poly_svc=SVC(kernel='poly', C=1.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "poly_svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=poly_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
      ],
      "metadata": {
        "id": "yf07UPJSSJE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate classifier with polynomial kernel and C=100.0\n",
        "poly_svc100=SVC(kernel='poly', C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "poly_svc100.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=poly_svc100.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "7DbD6hmiSKjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate classifier with sigmoid kernel and C=1.0\n",
        "sigmoid_svc=SVC(kernel='sigmoid', C=1.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "sigmoid_svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=sigmoid_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with sigmoid kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
      ],
      "metadata": {
        "id": "w7QA_OJgSMpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate classifier with sigmoid kernel and C=100.0\n",
        "sigmoid_svc100=SVC(kernel='sigmoid', C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "sigmoid_svc100.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=sigmoid_svc100.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
      ],
      "metadata": {
        "id": "Vsy3kIOCSOVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Confusion Matrix and slice it into four pieces\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])"
      ],
      "metadata": {
        "id": "xzDXCPZRSQFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize confusion matrix with seaborn heatmap\n",
        "\n",
        "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
        "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
      ],
      "metadata": {
        "id": "7iwlGsSuSRp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "hu8BfTFKSScs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]"
      ],
      "metadata": {
        "id": "Tiz7YL4OSXXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n"
      ],
      "metadata": {
        "id": "jjJEsyOYSZVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification error : {0:0.4f}'.format(classification_error))\n"
      ],
      "metadata": {
        "id": "XSXXw4_1SanT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print precision score\n",
        "\n",
        "precision = TP / float(TP + FP)\n",
        "\n",
        "\n",
        "print('Precision : {0:0.4f}'.format(precision))\n"
      ],
      "metadata": {
        "id": "4tax9wORSsmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall = TP / float(TP + FN)\n",
        "\n",
        "print('Recall or Sensitivity : {0:0.4f}'.format(recall))"
      ],
      "metadata": {
        "id": "nFWo5rIeSuQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_positive_rate = TP / float(TP + FN)\n",
        "\n",
        "\n",
        "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))"
      ],
      "metadata": {
        "id": "TcZCnpGSSwgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "false_positive_rate = FP / float(FP + TN)\n",
        "\n",
        "\n",
        "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))"
      ],
      "metadata": {
        "id": "urYDF0EeSx9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print('Specificity : {0:0.4f}'.format(specificity))"
      ],
      "metadata": {
        "id": "szN_Y4_oSz8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot ROC Curve\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "\n",
        "plt.plot(fpr, tpr, linewidth=2)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--' )\n",
        "\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "plt.title('ROC curve for Predicting a Pulsar Star classifier')\n",
        "\n",
        "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "\n",
        "plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R1ivVWMhS1l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute ROC AUC\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "ROC_AUC = roc_auc_score(y_test, y_pred_test)\n",
        "\n",
        "print('ROC AUC : {:.4f}'.format(ROC_AUC))"
      ],
      "metadata": {
        "id": "Cq9rw0yOS57T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate cross-validated ROC AUC \n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "Cross_validated_ROC_AUC = cross_val_score(linear_svc, X_train, y_train, cv=10, scoring='roc_auc').mean()\n",
        "\n",
        "print('Cross validated ROC AUC : {:.4f}'.format(Cross_validated_ROC_AUC))"
      ],
      "metadata": {
        "id": "OdVL-P6DTAkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "kfold=KFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "\n",
        "linear_svc=SVC(kernel='linear')\n",
        "\n",
        "\n",
        "linear_scores = cross_val_score(linear_svc, X, y, cv=kfold)\n"
      ],
      "metadata": {
        "id": "FMRMC9f7TCXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print cross-validation scores with linear kernel\n",
        "\n",
        "print('Stratified cross-validation scores with linear kernel:\\n\\n{}'.format(linear_scores))"
      ],
      "metadata": {
        "id": "2cjMkZohTD_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print average cross-validation score with linear kernel\n",
        "\n",
        "print('Average stratified cross-validation score with linear kernel:{:.4f}'.format(linear_scores.mean()))"
      ],
      "metadata": {
        "id": "1ZNp7KE6TFYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rbf_svc=SVC(kernel='rbf')\n",
        "\n",
        "\n",
        "rbf_scores = cross_val_score(rbf_svc, X, y, cv=kfold)"
      ],
      "metadata": {
        "id": "nwyrL5_0TG7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print cross-validation scores with rbf kernel\n",
        "\n",
        "print('Stratified Cross-validation scores with rbf kernel:\\n\\n{}'.format(rbf_scores))"
      ],
      "metadata": {
        "id": "UguyoB4NTIfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print average cross-validation score with rbf kernel\n",
        "\n",
        "print('Average stratified cross-validation score with rbf kernel:{:.4f}'.format(rbf_scores.mean()))"
      ],
      "metadata": {
        "id": "fR2YkiakTKUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print average cross-validation score with rbf kernel\n",
        "\n",
        "print('Average stratified cross-validation score with rbf kernel:{:.4f}'.format(rbf_scores.mean()))"
      ],
      "metadata": {
        "id": "q_WQVo5PTOHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine the best model\n",
        "\n",
        "\n",
        "# best score achieved during the GridSearchCV\n",
        "print('GridSearch CV best score : {:.4f}\\n\\n'.format(grid_search.best_score_))\n",
        "\n",
        "\n",
        "# print parameters that give the best results\n",
        "print('Parameters that give the best results :','\\n\\n', (grid_search.best_params_))\n",
        "\n",
        "\n",
        "# print estimator that was chosen by the GridSearch\n",
        "print('\\n\\nEstimator that was chosen by the search :','\\n\\n', (grid_search.best_estimator_))"
      ],
      "metadata": {
        "id": "lRjXxGh2TP4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate GridSearch CV score on test set\n",
        "\n",
        "print('GridSearch CV score on test set: {0:0.4f}'.format(grid_search.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "IAm_LG9_TPsC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}